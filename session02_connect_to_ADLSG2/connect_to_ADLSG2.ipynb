{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b0745e5f-f049-4b5f-810d-bcda392ac6bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# üíæ Acceso a Azure Data Lake Storage (ADLS Gen2) desde Databricks\n",
    "\n",
    "Este diagrama ilustra c√≥mo **Databricks** se conecta y accede a los datos almacenados en **Azure Data Lake Storage Gen2 (ADLS Gen2)**.\n",
    "\n",
    "---\n",
    "\n",
    "## üíª Componentes Principales\n",
    "\n",
    "* **Databricks:** La plataforma de an√°lisis.\n",
    "    * **Cluster:** El recurso computacional que ejecuta las tareas.\n",
    "    * **Notebook:** El entorno donde escribes y ejecutas el c√≥digo (por ejemplo, Python o SQL).\n",
    "* **Azure:** El proveedor de la nube.\n",
    "    * **Storage Account:** El contenedor que aloja los datos.\n",
    "    * **ADLS Gen2:** La capa de almacenamiento optimizada para Big Data.\n",
    "\n",
    "---\n",
    "\n",
    "## üîë M√©todos de Autenticaci√≥n y Seguridad\n",
    "\n",
    "Para que el Cluster/Notebook de Databricks pueda leer o escribir en ADLS Gen2, necesita autenticarse. Los m√©todos de autenticaci√≥n comunes son:\n",
    "\n",
    "### 1. Service Principal (Microsoft Entra ID/Azure Active Directory) üõ°Ô∏è\n",
    "\n",
    "* Es el m√©todo **m√°s recomendado** y seguro para entornos de producci√≥n.\n",
    "* Se utiliza una identidad de aplicaci√≥n (el **Service Principal**) registrada en **Microsoft Entra ID** (anteriormente Azure AD) para obtener acceso.\n",
    "\n",
    "### 2. Storage Access Keys üîë\n",
    "\n",
    "* Claves maestras que otorgan **acceso completo** a la cuenta de almacenamiento.\n",
    "* **No son recomendadas** para acceso de producci√≥n debido a que si se filtran, comprometen toda la cuenta.\n",
    "\n",
    "### 3. Shared Access Signature (SAS Token) üîó\n",
    "\n",
    "* Tokens temporales que otorgan acceso **limitado** (por tiempo, permisos y recursos espec√≠ficos) a los datos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5924fedb-d13e-4c58-a2ec-be8c3145f553",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####Storage Access Keys \n",
    "Para acceder a crear un secrectScope en databricks dirigite\n",
    "al home de databricks y agrega en la url esto: #secrets/createScope\n",
    "1. Establecer la configuraci√≥n de spark \"fs.azure.account.key\"\n",
    "2. Listar archivos del contenedor \"bronze\"\n",
    "3. Leer datos del archivo \"categorias.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b4c7d62-f954-4a6b-82ed-55a15c0fd127",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\n",
    "    \"fs.azure.account.key.adlsg2udemycourse.dfs.core.windows.net\",\n",
    "    dbutils.secrets.get(scope=\"sc-proyect-joseph\", key=\"key-adlsg2udemycourse\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1316b009-3716-4db1-b4cf-ada078ffa6e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Sin nosabemos el nombre del scope\n",
    "dbutils.secrets.listScopes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0312d561-f98e-48d2-909d-f8052f6e4ec0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Para listar tus secretos en adlsg\n",
    "dbutils.secrets.list(\"sc-proyect-joseph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "721941d0-8e1f-4d90-9874-bea163641b6d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# PARA LISTAR LOS ARCHIVOS QUE TENEMOS EN EL STORAGE ACCOUNT\n",
    "display(\n",
    "dbutils.fs.ls(\"abfss://bronze@adlsg2udemycourse.dfs.core.windows.net/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9f84ed9-c77c-456b-bca4-4a18a21b3423",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_categorias=spark.read.csv(\"abfss://bronze@adlsg2udemycourse.dfs.core.windows.net/categorias.csv\",header=True).limit(5).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8021d7db-f702-4e6f-94ca-1b3a73ffad04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "####Token SAS(SHARED ACCESS SIGNATURE)\n",
    "Para acceder a crear un secrectScope en databricks dirigite\n",
    "al home de databricks y agrega en la url esto: #secrets/createScope\n",
    "1. Establecer la configuraci√≥n de spark \"fs.azure.account.key\"\n",
    "2. Listar archivos del contenedor \"bronze\"\n",
    "3. Leer datos del archivo \"categorias.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03f85ce8-05a2-4607-afcf-42fdaaa25f90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"fs.azure.account.auth.type.adlsg2proyectudemy.dfs.core.windows.net\", \"SAS\")\n",
    "spark.conf.set(\"fs.azure.sas.token.provider.type.adlsg2proyectudemy.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.sas.FixedSASTokenProvider\")\n",
    "spark.conf.set(\"fs.azure.sas.fixed.token.adlsg2proyectudemy.dfs.core.windows.net\", dbutils.secrets.get(scope=\"sc-udemy-course\", key=\"secrect-sas\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "752d89b6-396b-4f4c-97bb-adffca2aa572",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#ESTO ES PAREA VISUALIZAR LA LISTA DE SCOPES CREADOS EN DATABRICKS\n",
    "dbutils.secrets.listScopes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ada5d942-810d-49ae-9952-70ad3baae9f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.secrets.list(\"sc-udemy-course\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f898dfdd-40a4-4540-b0ce-168480ef31f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_categorias=spark.read.csv(\"abfss://bronze@adlsg2proyectudemy.dfs.core.windows.net/categorias.csv\",header=True).limit(5).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "302a189b-0c74-4b73-a86c-249f08e33ca1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üîê Acceso Seguro a Azure Data Lake Gen2 desde Databricks (Service Principal)\n",
    "\n",
    "Este documento detalla los pasos y el flujo de trabajo para configurar el acceso seguro a **Azure Data Lake Storage Gen2 (ADLS Gen2)** desde un cl√∫ster de **Azure Databricks** utilizando un **Service Principal (Entidad de Servicio)** registrado en Microsoft Entra ID (antes Azure Active Directory) y el control de acceso basado en roles (**RBAC**).\n",
    "\n",
    "---\n",
    "\n",
    "## üèóÔ∏è Flujo de Acceso\n",
    "\n",
    "El diagrama ilustra el flujo de autenticaci√≥n y autorizaci√≥n:\n",
    "\n",
    "* **Databricks** necesita acceder a los datos almacenados en **ADLS Gen2** (que se representa con los iconos de SQL, Data Lakes y otros servicios).\n",
    "* La autenticaci√≥n se realiza a trav√©s de **Microsoft Entra ID**. Databricks utiliza una identidad registrada:\n",
    "    * **User Account** (Cuenta de Usuario) o, m√°s com√∫nmente para servicios automatizados,\n",
    "    * **Service Principal** (Entidad de Servicio), que act√∫a como una identidad no interactiva para la aplicaci√≥n.\n",
    "* El **Service Principal** debe tener asignado un **Rol de RBAC** (Role-Based Access Control) a nivel del **Resource Group** o la cuenta de almacenamiento de ADLS Gen2 para poder acceder.\n",
    "* El rol asignado (**Owner**, **Contributor**, **Storage Blob Data Contributor**, **Custom**, etc.) determina los permisos que el Service Principal tendr√° sobre los datos y la infraestructura.\n",
    "\n",
    "---\n",
    "\n",
    "## üõ†Ô∏è Pasos de Configuraci√≥n Requeridos\n",
    "\n",
    "Para implementar esta conexi√≥n de forma segura, se deben seguir los siguientes pasos clave:\n",
    "\n",
    "### 1. Preparaci√≥n en Microsoft Entra ID (Azure Portal)\n",
    "\n",
    "* **Registrar la Aplicaci√≥n en Microsoft Entra ID / Server Principal**: Se crea un registro de aplicaci√≥n. Esto genera un **Application ID (Client ID)** y un **Directory ID (Tenant ID)** √∫nicos.\n",
    "* **Generar un secreto (contrase√±a) para la Aplicaci√≥n**: Se crea un secreto de cliente asociado a la aplicaci√≥n registrada. Este secreto es la \"contrase√±a\" que Databricks usar√° para autenticarse.\n",
    "\n",
    "### 2. Autorizaci√≥n (RBAC)\n",
    "\n",
    "* **Asignar el Rol \"Storage Blob Data Contributor\" al Data Lake**: Este es el rol m√°s com√∫n y con el **m√≠nimo privilegio** necesario para leer, escribir y eliminar datos en contenedores y blobs de ADLS Gen2. Este rol se asigna al **Service Principal** en el alcance de la cuenta de almacenamiento o un contenedor espec√≠fico.\n",
    "\n",
    "### 3. Configuraci√≥n en Databricks (Spark)\n",
    "\n",
    "* **Configurar Spark con App / Client Id, Directory / Tenant Id & Secret**: El c√≥digo de Spark o la configuraci√≥n del cl√∫ster de Databricks debe recibir las credenciales del Service Principal para poder autenticarse. Esto se hace t√≠picamente estableciendo propiedades de configuraci√≥n de Spark en el notebook o el cl√∫ster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0c4e75a-d905-4da2-8da4-2e35dad180f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#obteniendo credenciales como tenan id , client id\n",
    "client_id=\"2a547da5-f769-4d90-83af-145052c0496a\"\n",
    "tenant_id=\"b824ae35-fbf9-4eaa-b4da-79ef1f190582\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e204ab79-f565-4201-9780-902dff0c0bba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.secrets.listScopes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc0f6b62-7786-41cb-b960-e0adaa7a06fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Esto te da los secretos creados en azure key vault\n",
    "dbutils.secrets.list(\"sc-udemy-course\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26fe6ba3-3bd9-4f6c-a51f-3c51afc1134f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "client_secret= dbutils.secrets.get(scope=\"sc-udemy-course\",key=\"client-secret-udemy\")\n",
    "\n",
    "spark.conf.set(\"fs.azure.account.auth.type.adlsg2proyectudemy.dfs.core.windows.net\", \"OAuth\")\n",
    "spark.conf.set(\"fs.azure.account.oauth.provider.type.adlsg2proyectudemy.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\n",
    "spark.conf.set(\"fs.azure.account.oauth2.client.id.adlsg2proyectudemy.dfs.core.windows.net\", f\"{client_id}\")\n",
    "spark.conf.set(\"fs.azure.account.oauth2.client.secret.adlsg2proyectudemy.dfs.core.windows.net\",client_secret)\n",
    "spark.conf.set(\"fs.azure.account.oauth2.client.endpoint.adlsg2proyectudemy.dfs.core.windows.net\", f\"https://login.microsoftonline.com/{tenant_id}/oauth2/token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a58df3f-45e0-4170-9788-4dbe9d32a1d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_categorias=spark.read.csv(\"abfss://bronze@adlsg2proyectudemy.dfs.core.windows.net/categorias.csv\",header=True).limit(5).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2c37fbf9-0efe-4a50-8643-cc55f78fc86e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üîë Autenticaci√≥n Centralizada: √Åmbito de Cl√∫ster (Cluster-Scoped Authentication)\n",
    "\n",
    "Este m√©todo es para que los usuarios accedan a datos en **Azure Data Lake Storage Gen2 (ADLS Gen2)** de forma segura, canalizando las credenciales de autenticaci√≥n a trav√©s de la configuraci√≥n de un cl√∫ster de Azure Databricks.\n",
    "\n",
    "Este enfoque asegura que las credenciales **no est√©n expuestas directamente en el c√≥digo del notebook**, sino que se gestionen a nivel de la infraestructura de c√≥mputo.\n",
    "\n",
    "---\n",
    "\n",
    "### üèóÔ∏è Flujo de Acceso\n",
    "\n",
    "* **User (Usuario)**: El usuario interact√∫a con un **Notebook** de Databricks.\n",
    "* **Notebook**: El c√≥digo dentro del notebook (por ejemplo, PySpark o Scala) contiene comandos de lectura/escritura de datos, pero **no contiene las credenciales sensibles** (como las Access Keys o los Service Principal Secrets).\n",
    "* **Cluster (Cl√∫ster)**: El notebook ejecuta el c√≥digo sobre un **Cl√∫ster** de Databricks. La clave de este m√©todo es que el cl√∫ster est√° configurado con las propiedades de autenticaci√≥n.\n",
    "    * **Secrets**: Las credenciales reales (generalmente un Service Principal ID y su Secreto, o un OAuth Token) se almacenan de forma segura en **Databricks Secret Scopes**.\n",
    "    * Estas propiedades se inyectan en la **Configuraci√≥n de Spark** del cl√∫ster antes de que comience a ejecutarse el c√≥digo del usuario.\n",
    "* **ADLS Gen2**: Cuando el c√≥digo del notebook intenta acceder a la ruta de ADLS Gen2, el cl√∫ster utiliza las credenciales preconfiguradas en su √°mbito para autenticarse y acceder a los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1bdb3ba4-859e-470b-94be-38b59ee6553f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "connect_to_ADLSG2",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
