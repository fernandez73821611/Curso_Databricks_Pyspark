{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fde53b23-541a-47c9-aff7-321ad30add98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# üß± Montaje (Mount) en Azure Databricks ‚Äî Actualizado 2025\n",
    "\n",
    "## üìò Concepto\n",
    "El **montaje (mount)** en **Azure Databricks** consiste en crear un alias o punto de montaje dentro del sistema de archivos de Databricks (DBFS ‚Äî *Databricks File System*) que apunta a una ubicaci√≥n de almacenamiento en la nube, como **Azure Blob Storage** o **Azure Data Lake Storage Gen2**.  \n",
    "\n",
    "Este alias permite acceder a los datos usando rutas simples como `/mnt/<nombre>` en lugar de usar las largas URLs de almacenamiento (por ejemplo, `abfss://...`).  \n",
    "\n",
    "> üìÖ **Nota actual (2025):**  \n",
    "> El uso de montajes se considera una **funcionalidad heredada** (*legacy access pattern*).  \n",
    "> Databricks y Microsoft recomiendan actualmente utilizar **Unity Catalog** para la gesti√≥n de accesos y permisos sobre el almacenamiento.  \n",
    ">  \n",
    "> üîó [Referencia oficial ‚Äî Microsoft Learn](https://learn.microsoft.com/en-us/azure/databricks/connect/storage/azure-storage)\n",
    "\n",
    "---\n",
    "\n",
    "## üíª Ejemplo de uso en un Notebook de Databricks\n",
    "\n",
    "```python\n",
    "# Montar un contenedor de Azure Data Lake Storage Gen2 en Databricks\n",
    "\n",
    "dbutils.fs.mount(\n",
    "    source = \"abfss://<contenedor>@<cuenta-almacenamiento>.dfs.core.windows.net/\",\n",
    "    mount_point = \"/mnt/<nombre_del_montaje>\",\n",
    "    extra_configs = {\n",
    "        \"fs.azure.account.auth.type.<cuenta-almacenamiento>.dfs.core.windows.net\": \"OAuth\",\n",
    "        \"fs.azure.account.oauth.provider.type.<cuenta-almacenamiento>.dfs.core.windows.net\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",\n",
    "        \"fs.azure.account.oauth2.client.id.<cuenta-almacenamiento>.dfs.core.windows.net\": \"<application-id>\",\n",
    "        \"fs.azure.account.oauth2.client.secret.<cuenta-almacenamiento>.dfs.core.windows.net\": dbutils.secrets.get(scope=\"<scope>\", key=\"<key>\"),\n",
    "        \"fs.azure.account.oauth2.client.endpoint.<cuenta-almacenamiento>.dfs.core.windows.net\": \"https://login.microsoftonline.com/<directory-id>/oauth2/token\"\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "46f0c7af-e1c1-44de-8568-eb65bb5d4ec7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# üß± Montar (Mount) Azure Data Lake Storage Gen2 en Databricks mediante Service Principal\n",
    "\n",
    "## üîπ Descripci√≥n general\n",
    "Este proceso permite conectar Azure Databricks con Azure Data Lake Storage (ADLS Gen2) de forma segura usando un **Service Principal** registrado en **Microsoft Entra ID (Azure AD)**.  \n",
    "De esta manera, podr√°s acceder a los datos desde rutas locales (`/mnt/...`) en el sistema de archivos de Databricks (DBFS).\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Pasos para realizar el montaje\n",
    "\n",
    "### 1Ô∏è‚É£ Obtener credenciales seguras desde Azure Key Vault\n",
    "Antes de montar el almacenamiento, necesitas los valores siguientes, que puedes guardar como secretos en **Azure Key Vault** o en un **Databricks Secret Scope**:\n",
    "\n",
    "- **Client ID (application id)**  \n",
    "- **Tenant ID (directory id)**  \n",
    "- **Client Secret (password del Service Principal)**  \n",
    "\n",
    "> üí° *Recomendaci√≥n:* Guarda estos valores en Azure Key Vault e int√©gralo con Databricks para no exponer credenciales directamente en el c√≥digo.  \n",
    "> üîó [Integrar Key Vault con Databricks](https://learn.microsoft.com/en-us/azure/databricks/security/secrets/secret-scopes)\n",
    "\n",
    "---\n",
    "\n",
    "### 2Ô∏è‚É£ Configurar variables en Databricks (Service Principal)\n",
    "Define los par√°metros necesarios para la autenticaci√≥n con tu Service Principal.\n",
    "\n",
    "```python\n",
    "storage_account_name = \"<nombre_cuenta_storage>\"\n",
    "container_name = \"<nombre_contenedor>\"\n",
    "mount_point = \"/mnt/<nombre_montaje>\"\n",
    "\n",
    "client_id = dbutils.secrets.get(scope=\"<scope>\", key=\"client-id\")\n",
    "tenant_id = dbutils.secrets.get(scope=\"<scope>\", key=\"tenant-id\")\n",
    "client_secret = dbutils.secrets.get(scope=\"<scope>\", key=\"client-secret\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eba2d56c-274e-4597-9e1a-8e335a12814d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.secrets.listScopes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2601e513-e078-42b1-b777-74d50178b75d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.secrets.list(\"sc-udemy-course\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de148de5-1527-4573-9c2b-c05d8149ef32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "client_id=dbutils.secrets.get(scope=\"sc-udemy-course\",key=\"client-id-proyect-joseph\")\n",
    "tenan_id=dbutils.secrets.get(scope=\"sc-udemy-course\",key=\"tenan-id-proyect-joseph\")\n",
    "client_secret=dbutils.secrets.get(scope=\"sc-udemy-course\",key=\"secret-client-proyect-joseph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bbd810f-b233-4f17-9a1c-be0daeec2488",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "name_storage=\"adlsg2proyectudemy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d33a0f31-a81e-42ef-9309-e1fc7dddfc37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "configs = {\"fs.azure.account.auth.type\": \"OAuth\",\n",
    "          \"fs.azure.account.oauth.provider.type\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",\n",
    "          \"fs.azure.account.oauth2.client.id\": client_id,\n",
    "          \"fs.azure.account.oauth2.client.secret\": client_secret,\n",
    "          \"fs.azure.account.oauth2.client.endpoint\": f\"https://login.microsoftonline.com/{tenan_id}/oauth2/token\"}\n",
    "\n",
    "# Optionally, you can add <directory-name> to the source URI of your mount point.\n",
    "dbutils.fs.mount(\n",
    "  source = f\"abfss://bronze@{name_storage}.dfs.core.windows.net/\",\n",
    "  mount_point = f\"/mnt/{name_storage}/bronze\",  #una buena practica es nombre storage / nombre de container\n",
    "  extra_configs = configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9d0a921-f418-4afd-80f3-18aa22f31690",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_categorias=spark.read.csv(f\"/mnt/adlsg2proyectudemy/bronze/categorias.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce72adbc-d059-4257-bf72-b4aeb4be863f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_categorias.limit(5).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00be53c2-f77d-4248-94c5-e25f786f2813",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"mountPoint\":261,\"source\":348},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1762824027539}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#para ver los montajes\n",
    "display(dbutils.fs.mounts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a8aaaa8-0268-4cb0-a087-8e735a0e7ef2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#PARA PODER DESMONTAR\n",
    "dbutils.fs.unmount(\"/mnt/adlsg2proyectudemy/bronze\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8303ac10-c16c-4988-baed-839dc041395d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#para ver los montajes\n",
    "display(dbutils.fs.mounts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf64fbb1-c04f-46c0-a1f5-c5882c4d7731",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# üß© UDF (User Defined Functions) en Spark / Databricks\n",
    "\n",
    "## üìò Concepto\n",
    "Las **UDF (User Defined Functions)** son **funciones definidas por el usuario** que permiten extender las capacidades de **Spark SQL o PySpark**.  \n",
    "Se utilizan cuando las funciones integradas de Spark no son suficientes para realizar una operaci√≥n espec√≠fica sobre los datos.\n",
    "\n",
    "Con una UDF, puedes crear tu propia l√≥gica en **Python, Scala o Java**, y aplicarla a columnas de un DataFrame como si fuera una funci√≥n nativa de Spark.\n",
    "\n",
    "---\n",
    "\n",
    "## üíª Ejemplo en PySpark\n",
    "\n",
    "```python\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Definir funci√≥n Python\n",
    "def mayusculas(texto):\n",
    "    return texto.upper() if texto else None\n",
    "\n",
    "# Registrar como UDF en Spark\n",
    "udf_mayusculas = udf(mayusculas, StringType())\n",
    "\n",
    "# Aplicar la UDF a una columna\n",
    "df = df.withColumn(\"nombre_mayus\", udf_mayusculas(df[\"nombre\"]))\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "181cea52-a6ce-4899-8a04-60f3259d32d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### MONTAJE DE TODOS LOS CANTAINERS DE MI AZURE DATA LAKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02789675-396a-4264-b0e8-2e3a528f44a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "[mount.mountPoint for mount in dbutils.fs.mounts()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "702e7a12-1e7e-41ea-90e6-28424829f1b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def mount_adls_udf(client_id,tenan_id,client_secret,name_storage,name_container):\n",
    "    configs = {\"fs.azure.account.auth.type\": \"OAuth\",\n",
    "          \"fs.azure.account.oauth.provider.type\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",\n",
    "          \"fs.azure.account.oauth2.client.id\": client_id,\n",
    "          \"fs.azure.account.oauth2.client.secret\": client_secret,\n",
    "          \"fs.azure.account.oauth2.client.endpoint\": f\"https://login.microsoftonline.com/{tenan_id}/oauth2/token\"}\n",
    "    \n",
    "    #si ya existe el montaje lo vamos a desmontar\n",
    "    if any(mount.mountPoint == f\"/mnt/{name_storage}/{name_container}\" for mount in dbutils.fs.mounts()):\n",
    "        dbutils.fs.unmount(f\"/mnt/{name_storage}/{name_container}\")\n",
    "\n",
    "# Optionally, you can add <directory-name> to the source URI of your mount point.\n",
    "    dbutils.fs.mount(\n",
    "        source = f\"abfss://{name_container}@{name_storage}.dfs.core.windows.net/\",\n",
    "         mount_point = f\"/mnt/{name_storage}/{name_container}\",  #una buena practica es nombre storage / nombre de container\n",
    "        extra_configs = configs)\n",
    "    \n",
    "    display(dbutils.fs.mounts())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5777e806-008f-44fd-90b0-a10e706d1a2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#utilizando la funcion\n",
    "mount_adls_udf(client_id,tenan_id,client_secret,\"adlsg2proyectudemy\",\"silver\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5eaa0835-179e-4664-a582-0adfc6cf67a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mount_adls_udf(client_id,tenan_id,client_secret,\"adlsg2proyectudemy\",\"gold\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Mount_and_UDF",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
